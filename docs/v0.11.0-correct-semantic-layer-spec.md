# Agent-Audit v0.11.0 正确的语义层设计

**版本**: v0.11.0  
**状态**: 待实施  
**问题**: v0.10.0 采用了错误的黑名单方向，需要彻底重构

---

## 1. v0.10.0 错误分析

### 错误方向 (v0.10.0 实际做的)

```
❌ AGENT-034: 检测到危险操作 → 检查是否在 SAFE_BUILTIN_CALLS 黑名单中
❌ AGENT-018: 检查变量名是否匹配 BUILTIN_VARIABLE_PATTERNS 正则
```

**问题**:
1. 60+ 函数黑名单治标不治本，新的标准库调用会漏
2. 变量名匹配不可靠：`data.add(user_input)` 会漏，`memory_set.add()` 会误放

### 正确方向 (v0.11.0 应该做的)

```
✅ AGENT-034: 先识别 Agent tool 入口 → 只在 tool 内检测是否有验证
✅ AGENT-018: 识别具体的 Agent 记忆组件方法 → 只对这些方法触发
```

**核心思路**: 收紧触发条件，而不是放松排除条件

---

## 2. AGENT-034 正确设计

### 2.1 问题根因

当前逻辑检测 "函数体内有 subprocess.run/exec 等"，但没有区分：
- 这个函数是不是 Agent tool 入口？
- 用户输入是否真的会流入这些危险调用？

### 2.2 正确触发条件

**只有同时满足以下条件才触发 AGENT-034**:

```
1. 函数是 Agent Tool 入口:
   - 有 @tool 装饰器
   - 是 BaseTool/StructuredTool 的 _run()/_arun() 方法
   - 是 FunctionTool 的处理函数
   
2. 函数接受外部输入参数:
   - 有 str/Any 类型参数（非 self/cls）
   
3. 外部输入流向危险操作:
   - subprocess.run/call/Popen(command) 其中 command 来自参数
   - exec/eval(code) 其中 code 来自参数
   - cursor.execute(sql) 其中 sql 来自参数
   
4. 没有检测到输入验证:
   - 没有 isinstance/type check
   - 没有 allowlist/denylist 检查
   - 没有 validation 函数调用
```

### 2.3 为什么这样设计能解决问题

**场景: asyncio.run() 误报**
```python
# v0.10.0 错误方案: 需要把 asyncio.run 加入 60+ 黑名单
# v0.11.0 正确方案: 这个函数不是 @tool 入口，直接跳过

async def main():
    result = await asyncio.gather(...)  # 不是 tool，不检测
    return result

if __name__ == "__main__":
    asyncio.run(main())  # 不是 tool，不检测
```

**场景: 真正的 tool 危险操作**
```python
@tool
def shell_tool(command: str) -> str:  # ✓ @tool 入口
    """Execute shell command."""     # ✓ str 参数
    result = subprocess.run(command, shell=True)  # ✓ 参数流向危险操作
    return result.stdout  # ✓ 无验证
    # → 触发 AGENT-034 ✓
```

### 2.4 实现代码

```python
# agent_audit/analysis/tool_boundary_detector.py

"""
Tool Boundary Detection for AGENT-034.

Core principle: Only check for input validation within Agent Tool entry points.
NOT using blacklists - instead tightening trigger conditions.
"""

import ast
from dataclasses import dataclass
from typing import Optional, Set, List

# Agent Tool entry point indicators
TOOL_DECORATORS: Set[str] = {
    'tool',           # @tool (LangChain)
    'function_tool',  # LlamaIndex
    'kernel_function', # Semantic Kernel
}

TOOL_CLASS_METHODS: Set[str] = {
    '_run',      # BaseTool._run()
    '_arun',     # BaseTool._arun()
    'run',       # Direct run method
    'arun',      # Async run
    'invoke',    # RunnableLambda.invoke()
    'ainvoke',   # Async invoke
}

TOOL_BASE_CLASSES: Set[str] = {
    'BaseTool', 'Tool', 'StructuredTool',
    'FunctionTool', 'QueryEngineTool',
    'RunnableLambda', 'RunnableSequence',
}


@dataclass
class ToolBoundaryResult:
    """Result of tool boundary analysis."""
    is_tool_entry: bool
    reason: str
    tool_type: Optional[str] = None  # 'decorator', 'class_method', 'none'


def is_tool_entry_point(node: ast.FunctionDef, class_name: Optional[str] = None) -> ToolBoundaryResult:
    """
    Check if a function is an Agent Tool entry point.
    
    This is the ONLY gate for AGENT-034 - if this returns False,
    we skip ALL further checks. No blacklists needed.
    """
    # Check 1: Has @tool decorator
    for decorator in node.decorator_list:
        dec_name = _get_decorator_name(decorator)
        if dec_name in TOOL_DECORATORS:
            return ToolBoundaryResult(
                is_tool_entry=True,
                reason=f"Has @{dec_name} decorator",
                tool_type='decorator'
            )
    
    # Check 2: Is _run()/_arun() method in a Tool class
    if class_name and node.name in TOOL_CLASS_METHODS:
        # Need to verify class inherits from Tool base
        # This would be set by the parent class visitor
        return ToolBoundaryResult(
            is_tool_entry=True,
            reason=f"Method {node.name}() in {class_name}",
            tool_type='class_method'
        )
    
    # Check 3: Function name contains 'tool' (weak signal, lower confidence)
    if 'tool' in node.name.lower():
        # Only if it also has str parameters - very weak heuristic
        has_str_param = any(
            _get_annotation_type(arg.annotation) in ('str', 'Any')
            for arg in node.args.args if arg.arg not in ('self', 'cls')
        )
        if has_str_param:
            return ToolBoundaryResult(
                is_tool_entry=True,
                reason=f"Function name contains 'tool': {node.name}",
                tool_type='name_heuristic'
            )
    
    # Not a tool entry point - SKIP all AGENT-034 checks
    return ToolBoundaryResult(
        is_tool_entry=False,
        reason="Not a Tool entry point",
        tool_type='none'
    )


def _get_decorator_name(node: ast.expr) -> str:
    """Extract decorator name."""
    if isinstance(node, ast.Name):
        return node.id
    elif isinstance(node, ast.Attribute):
        return node.attr
    elif isinstance(node, ast.Call):
        return _get_decorator_name(node.func)
    return ""


def _get_annotation_type(node: Optional[ast.expr]) -> str:
    """Get type annotation as string."""
    if node is None:
        return 'Any'
    if isinstance(node, ast.Name):
        return node.id
    if isinstance(node, ast.Constant):
        return str(node.value)
    return 'Any'
```

### 2.5 修改 python_scanner.py

```python
def _check_tool_no_input_validation(
    self, node: ast.FunctionDef
) -> Optional[Dict[str, Any]]:
    """
    AGENT-034: Detect tool functions without input validation.
    
    v0.11.0: Correct semantic layer - first identify Tool boundary,
    then check within boundary. NO BLACKLISTS.
    """
    # === GATE 1: Is this a Tool entry point? ===
    # This is the ONLY gate. If False, skip everything.
    boundary = is_tool_entry_point(node, self._current_class)
    
    if not boundary.is_tool_entry:
        return None  # NOT a tool - don't check anything
    
    # === From here, we KNOW this is a Tool entry point ===
    
    # Check for string parameters
    str_params = self._get_str_params(node)
    if not str_params:
        return None  # No string params, no injection risk
    
    # Check for input validation
    has_validation = self._has_input_validation(node, str_params)
    if has_validation:
        return None  # Has validation, safe
    
    # Check if params flow to dangerous operations
    dangerous_sink = self._find_dangerous_sink(node, str_params)
    if not dangerous_sink:
        return None  # Params don't flow to dangerous ops
    
    # Tool entry + str params + no validation + dangerous sink = REPORT
    return {
        'type': 'tool_no_input_validation',
        'function': node.name,
        'unvalidated_params': list(str_params),
        'dangerous_sink': dangerous_sink,
        'tool_type': boundary.tool_type,
        'line': node.lineno,
        'snippet': self._get_line(node.lineno),
        'owasp_id': 'ASI-02',
        'confidence': 0.9 if boundary.tool_type == 'decorator' else 0.7,
    }
```

---

## 3. AGENT-018 正确设计

### 3.1 问题根因

当前逻辑检测 "方法名是 add/append/set"，然后用变量名正则排除 Python 内置。

**这完全是反的** - 应该是只检测已知的 Agent 记忆组件方法。

### 3.2 正确触发条件

**只对以下具体方法触发 AGENT-018**:

```python
# Agent Memory Component Methods - WHITELIST (not blacklist!)
AGENT_MEMORY_METHODS: Dict[str, str] = {
    # LangChain Memory
    'add_message': 'langchain_memory',
    'add_user_message': 'langchain_memory',
    'add_ai_message': 'langchain_memory',
    'add_messages': 'langchain_memory',
    'save_context': 'langchain_memory',
    
    # Vector Stores
    'add_texts': 'vector_store',
    'add_documents': 'vector_store',
    'aadd_texts': 'vector_store',
    'aadd_documents': 'vector_store',
    'upsert': 'vector_store',
    
    # Generic Agent Memory
    'add_memory': 'agent_memory',
    'store_memory': 'agent_memory',
    'persist_memory': 'agent_memory',
    'save_memory': 'agent_memory',
    
    # CrewAI Memory
    'add_to_memory': 'crewai_memory',
    'store_in_memory': 'crewai_memory',
}

# Additional requirement: File must import Agent framework
AGENT_FRAMEWORKS = {'langchain', 'crewai', 'autogen', 'llama_index', ...}
```

### 3.3 为什么这样设计能解决问题

**场景: Python set() 误报 (Generative Agents)**
```python
# v0.10.0 错误方案: 检测 .add() 然后用变量名正则排除
# v0.11.0 正确方案: .add() 不在 AGENT_MEMORY_METHODS 白名单中，直接跳过

seen = set()
seen.add(agent_id)  # ← .add() 不在白名单，不检测
```

**场景: 真正的 Agent 内存操作**
```python
from langchain.memory import ConversationBufferMemory

memory = ConversationBufferMemory()
memory.add_message(user_input)  # ← add_message 在白名单，触发检测
# → AGENT-018 ✓
```

**场景: 边界案例**
```python
# data.add(user_input) - v0.10.0 可能漏掉（变量名不匹配）
# v0.11.0: .add() 不在白名单，正确跳过（这不是 Agent 内存操作）

# memory_set.add(malicious) - v0.10.0 可能误放（匹配 _set 后缀）  
# v0.11.0: .add() 不在白名单，正确跳过（这是 Python set，不是 Agent 内存）
```

### 3.4 实现代码

```python
# agent_audit/analysis/memory_operation_detector.py

"""
Agent Memory Operation Detection for AGENT-018.

Core principle: Use a WHITELIST of known Agent memory methods.
NOT using variable name heuristics - instead identifying specific methods.
"""

from typing import Dict, Set, Tuple, Optional

# Known Agent Memory Methods - WHITELIST
# Only these methods should trigger AGENT-018
AGENT_MEMORY_WRITE_METHODS: Dict[str, str] = {
    # LangChain Memory
    'add_message': 'langchain_memory',
    'add_user_message': 'langchain_memory',
    'add_ai_message': 'langchain_memory',
    'add_messages': 'langchain_memory',
    'save_context': 'langchain_memory',
    'load_memory_variables': 'langchain_memory',  # Write on first load
    
    # Vector Stores (common to multiple frameworks)
    'add_texts': 'vector_store',
    'add_documents': 'vector_store',
    'aadd_texts': 'vector_store',
    'aadd_documents': 'vector_store',
    'upsert': 'vector_store',
    'delete': 'vector_store',  # Also dangerous
    
    # LlamaIndex
    'insert': 'llama_index',
    'insert_nodes': 'llama_index',
    
    # CrewAI
    'add_to_memory': 'crewai',
    'kickoff': 'crewai',  # Executes with memory
    
    # Haystack
    'write_documents': 'haystack',
    
    # Generic patterns that are ALWAYS Agent memory (not Python builtins)
    'add_memory': 'generic_memory',
    'store_memory': 'generic_memory',
    'persist_memory': 'generic_memory',
    'save_memory': 'generic_memory',
    'update_memory': 'generic_memory',
}

# These generic methods need additional context check
AMBIGUOUS_METHODS: Set[str] = {
    'add',      # Could be set.add() or memory.add()
    'append',   # Could be list.append() or history.append()
    'update',   # Could be dict.update() or context.update()
    'set',      # Could be dict.set() or state.set()
}


def is_agent_memory_operation(
    method_name: str,
    receiver_type: Optional[str] = None,
    file_imports: Optional[Set[str]] = None,
) -> Tuple[bool, str]:
    """
    Check if a method call is an Agent memory operation.
    
    Args:
        method_name: Name of the method being called
        receiver_type: Type of the receiver object (if known)
        file_imports: Set of imports in the file
    
    Returns:
        (is_memory_op, reason)
    """
    # Check 1: Is method in the whitelist?
    if method_name in AGENT_MEMORY_WRITE_METHODS:
        framework = AGENT_MEMORY_WRITE_METHODS[method_name]
        return (True, f"Agent memory method: {method_name} ({framework})")
    
    # Check 2: Is method ambiguous and needs context?
    if method_name in AMBIGUOUS_METHODS:
        # For ambiguous methods, we need additional signals
        # Option A: Receiver type is known and is a memory class
        if receiver_type and _is_memory_class(receiver_type):
            return (True, f"Ambiguous method on memory class: {receiver_type}.{method_name}")
        
        # Option B: File imports Agent framework and receiver name suggests memory
        # This is a weak signal, but better than variable name regex
        # We could also require receiver_type to be known
        
        # Default: Skip ambiguous methods unless we have strong signals
        return (False, f"Ambiguous method, insufficient context: {method_name}")
    
    # Not an Agent memory method
    return (False, f"Not an Agent memory method: {method_name}")


def _is_memory_class(class_name: str) -> bool:
    """Check if class name indicates an Agent memory class."""
    memory_indicators = [
        'Memory', 'Store', 'Vector', 'Retriever', 'Index',
        'ConversationBuffer', 'ChatMessage', 'MessageHistory',
    ]
    return any(indicator in class_name for indicator in memory_indicators)
```

### 3.5 修改 python_scanner.py

```python
def _check_memory_poisoning(self, node: ast.Call) -> Optional[Dict[str, Any]]:
    """
    ASI-06: Detect unsanitized writes to Agent memory stores.
    
    v0.11.0: Use WHITELIST of Agent memory methods.
    NOT checking variable names - checking specific methods.
    """
    func_name = self._get_call_name(node)
    if not func_name:
        return None
    
    # Extract method name
    method_name = func_name.split('.')[-1] if '.' in func_name else func_name
    
    # === GATE: Is this an Agent memory method? ===
    # This uses a WHITELIST, not a blacklist
    is_memory, reason = is_agent_memory_operation(
        method_name=method_name,
        receiver_type=self._get_receiver_type(node),
        file_imports=self.imports,
    )
    
    if not is_memory:
        return None  # Not an Agent memory method, skip
    
    # === From here, we KNOW this is an Agent memory operation ===
    
    # Existing context analysis...
    analyzer = _get_memory_analyzer()
    ctx = analyzer.analyze(node, self.source, self.imports)
    
    # Return finding with context
    return {
        'type': 'unsanitized_memory_write',
        'function': func_name,
        'method': method_name,
        'memory_type': reason,
        'line': node.lineno,
        'confidence': ctx.confidence,
        # ... rest of existing fields ...
    }
```

---

## 4. 对比总结

### 方案对比

| 维度 | v0.10.0 错误方案 | v0.11.0 正确方案 |
|------|-----------------|-----------------|
| **方向** | 黑名单排除 | 白名单收紧 |
| **AGENT-034** | 60+ SAFE_BUILTIN_CALLS | Tool 入口检测 |
| **AGENT-018** | 变量名正则 | Agent 内存方法白名单 |
| **可维护性** | 需要不断补充黑名单 | 只需维护已知 Agent 方法 |
| **漏检风险** | 新标准库会漏 | 新 Agent 框架需要添加 |
| **误检风险** | 变量名猜测不可靠 | 白名单精确匹配 |

### 逻辑流程对比

**v0.10.0 错误流程**:
```
检测到 subprocess.run → 
在 SAFE_BUILTIN_CALLS 吗? → 
  是 → 跳过
  否 → 报告 (但可能不在 Tool 内!)
```

**v0.11.0 正确流程**:
```
是 Tool 入口吗? →
  否 → 跳过 (不需要任何黑名单!)
  是 → 有危险操作吗? →
    否 → 跳过
    是 → 参数流向危险操作吗? →
      否 → 跳过
      是 → 有验证吗? →
        是 → 跳过
        否 → 报告
```

---

## 5. 实施检查清单

### Phase 1: 删除错误代码

- [ ] 删除 `SAFE_BUILTIN_CALLS` 60+ 黑名单
- [ ] 删除 `BUILTIN_VARIABLE_PATTERNS` 正则
- [ ] 删除 `_is_dangerous_op_actually_safe_builtin()`
- [ ] 删除 `is_python_collection()` 变量名检测

### Phase 2: 实现正确逻辑

- [ ] 创建 `is_tool_entry_point()` Tool 入口检测
- [ ] 创建 `AGENT_MEMORY_WRITE_METHODS` 白名单
- [ ] 创建 `is_agent_memory_operation()` 方法检测
- [ ] 修改 `_check_tool_no_input_validation()` 使用 Tool 入口 gate
- [ ] 修改 `_check_memory_poisoning()` 使用方法白名单

### Phase 3: 测试

- [ ] 删除基于黑名单的测试用例
- [ ] 添加 Tool 入口检测测试
- [ ] 添加 Agent 内存方法白名单测试
- [ ] 运行 benchmark 验证

---

## 6. 预期结果

| Benchmark | v0.9.0 | v0.10.0 (错误) | v0.11.0 (正确) |
|-----------|--------|---------------|---------------|
| SWE-agent AGENT-034 | 33 | ~6 (黑名单) | ≤6 (Tool gate) |
| Generative Agents AGENT-018 | 11 | ~0 (正则) | 0 (方法白名单) |

**关键区别**: v0.11.0 达到相同效果，但使用的是可维护的正确方案，而不是脆弱的黑名单/正则方案。
